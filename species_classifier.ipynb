{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorboard\n",
    "%pip install fastai\n",
    "%pip install pypdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pypdl import Pypdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = Pypdl()\n",
    "#dl.start('https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = Pypdl()\n",
    "#dl.start('https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.json.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "marine_life_classes = [\"Actinopterygii\"]\n",
    "\n",
    "\"\"\" marine_life_classes = [\n",
    "    \"Actinopterygii\",\n",
    "    \"Gastropoda\",\n",
    "    \"Malacostraca\",\n",
    "    \"Bivalvia\",\n",
    "    \"Anthozoa\",\n",
    "    \"Elasmobranchii\",\n",
    "    \"Asteroidea\",\n",
    "    \"Polyplacophora\",\n",
    "    \"Hexanauplia\",\n",
    "    \"Echinoidea\",\n",
    "    \"Scyphozoa\",\n",
    "    \"Cephalopoda\",\n",
    "    \"Hydrozoa\",\n",
    "    \"Ascidiacea\",\n",
    "    \"Holothuroidea\",\n",
    "    \"Ophiuroidea\",\n",
    "] \"\"\"\n",
    "\n",
    "train_data = 'train_mini/train_mini'\n",
    "annotation_json = 'train_mini.json'\n",
    "\n",
    "train_file = \"train.tar.gz\"\n",
    "train_annotations_tar = \"train.json.tar.gz\"\n",
    "train_annotations = \"train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "import tarfile\n",
    "\n",
    "with tarfile.open(train_annotations_tar, \"r:gz\") as archive:\n",
    "    archive.extractall(path=\".\")\n",
    "\n",
    "with open(train_annotations) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    rows = [category_info.values() for category_info in data[\"categories\"]]\n",
    "    df = pd.DataFrame(rows, columns=data[\"categories\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"name\"] == \"Tursiops truncatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"class\"].isin(marine_life_classes)][\"common_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"class\"].isin(marine_life_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.callback.tensorboard import TensorBoardCallback\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_folders = set(df[\"image_dir_name\"].unique())\n",
    "\n",
    "extraction_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "members = []\n",
    "\n",
    "with tarfile.open(train_file, \"r:gz\") as archive:\n",
    "    members = archive.getmembers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(members[1].name.split(\"/\")[-1])\n",
    "\n",
    "filtered_members = [\n",
    "    member\n",
    "    for member in members\n",
    "    if len(member.name.split(\"/\")) > 1 and member.name.split(\"/\")[1] in extraction_folders\n",
    "]\n",
    "\n",
    "top_members = [member.name for member in members]\n",
    "\n",
    "len(filtered_members)\n",
    "\n",
    "print(filtered_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(train_file, \"r:gz\") as archive:\n",
    "    archive.extractall(\".\", members=filtered_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"train_mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfms = [\n",
    "    ToTensor(),\n",
    "    *aug_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.0),\n",
    "    Normalize(),\n",
    "]\n",
    "cells = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(256),\n",
    "    batch_tfms=batch_tfms,\n",
    ")\n",
    "\n",
    "dls = cells.dataloaders(path, bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=4, figsize=(12, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm that the shape of the data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.shape, yb.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See number of classes\n",
    "dls.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covolutional Neural Network\n",
    "\n",
    "We start by defining methods to create a convolutional neural network. The first method creates a convolutional layer with a kernel size of 3 and a stride of 2. The second method creates a ResBlock which is a BatchNormalization and ReLU function mixed in one. The third method creates a fully connected layer using the above two methods while adding a dropout layer to prevent overfitting and also a AdaptiveAvgPool2d layer to reduce the size of the image to 1x1 before passing it to AdaptiveMaxPool2d layer. The final layer is a linear layer withou any activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2(ni, nf):\n",
    "    return ConvLayer(ni, nf, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(Module):\n",
    "    def __init__(self, nf):\n",
    "        self.conv1 = ConvLayer(nf, nf)\n",
    "        self.conv2 = ConvLayer(nf, nf)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv2(self.conv1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn():\n",
    "    return nn.Sequential(\n",
    "        conv2(3, 16),\n",
    "        ResBlock(16),\n",
    "        conv2(16, 32),\n",
    "        ResBlock(32),\n",
    "        conv2(32, 64),\n",
    "        ResBlock(64),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        nn.AdaptiveMaxPool2d(1),\n",
    "        Flatten(),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Linear(64, dls.c),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls,\n",
    "    simple_cnn(),\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=[accuracy],\n",
    "    cbs=ActivationStats(with_hist=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping Callback to prevent overfitting and TensorBoardCallback to monitor the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('models/cell_detection'):\n",
    "  learn.load(path/'cell_detection')\n",
    "else:\n",
    "  learn.fit_one_cycle(20, 0.001, cbs=[TensorBoardCallback('tmp/runs/tb', trace_model=True), EarlyStoppingCallback(monitor='valid_loss', min_delta=0.1, patience=3)])\n",
    "  learn.export('models/cell_detection.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_sched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = Interpretation.from_learner(learn)\n",
    "interp.plot_top_losses(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(\"public_test.json.tar.gz\", \"r:gz\") as archive:\n",
    "    archive.extractall(path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = []\n",
    "\n",
    "with tarfile.open(\"public_test.tar.gz\", \"r:gz\") as archive:\n",
    "    archive.extractall(\"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dls = dls.test_dl(\n",
    "    get_image_files(\"test_data/\"), bs=32, with_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,targs = learn.get_preds(dl=test_dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds).float().argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap of the predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(targs, (preds>0.5).float().argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f',\n",
    "            xticklabels=dls.vocab, yticklabels=dls.vocab)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir='data/tmp/runs/tb'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
